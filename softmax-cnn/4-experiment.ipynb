{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Supervised Learning - Classification of birds to species with Convolutional Neural Network**\n",
    "\n",
    "Learning paradigm: (strong) supervised learning\n",
    "\n",
    "<u>This notebook documents 4. experiment conducted in 11th of April 2022</u>\n",
    "\n",
    "Dataset I work with is: https://www.kaggle.com/datasets/gpiosenka/100-bird-species/. Check what Convolutional neural networks are all about at https://d2l.ai/chapter_convolutional-neural-networks/index.html before making changes to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T19:48:30.702777Z",
     "iopub.status.busy": "2021-07-04T19:48:30.702432Z",
     "iopub.status.idle": "2021-07-04T19:48:38.452291Z",
     "shell.execute_reply": "2021-07-04T19:48:38.450907Z",
     "shell.execute_reply.started": "2021-07-04T19:48:30.702703Z"
    }
   },
   "outputs": [],
   "source": [
    "# import utilities\n",
    "import os\n",
    "import matplotlib.pyplot as plt # to evaluate model performance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "\n",
    "import tensorflow as tf # import tensorflow\n",
    "# work with Keras facade\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Activation, Dropout # input, output, hidden layers, activation...\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D # convolutional layer and max pooling\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training set consists of 58 388 RGB images (that means 3 channels), 224px x 224px. Validation set consists of 2000 images and test set consists of 2000 images. There are 356 unique bird species in a training dataset. There are 400 unique bird species in validation dataset and 400 bird species in test dataset too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T19:50:40.928323Z",
     "iopub.status.busy": "2021-07-04T19:50:40.928026Z",
     "iopub.status.idle": "2021-07-04T19:50:40.943859Z",
     "shell.execute_reply": "2021-07-04T19:50:40.943012Z",
     "shell.execute_reply.started": "2021-07-04T19:50:40.928295Z"
    }
   },
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd() # extract dataset from Kaggle to same folder as you have in this notebook\n",
    "\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, 'train')\n",
    "VALIDATION_DIR = os.path.join(BASE_DIR, 'valid')\n",
    "TEST_DIR = os.path.join(BASE_DIR, 'testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T19:50:45.326576Z",
     "iopub.status.busy": "2021-07-04T19:50:45.326284Z",
     "iopub.status.idle": "2021-07-04T19:50:45.362266Z",
     "shell.execute_reply": "2021-07-04T19:50:45.361629Z",
     "shell.execute_reply.started": "2021-07-04T19:50:45.326533Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_CATEGORIES = os.listdir(TRAIN_DIR)\n",
    "Train_Category_count = len(TRAIN_CATEGORIES) # gets you number of classes in training dataset\n",
    "\n",
    "VAL_CATEGORIES = os.listdir(VALIDATION_DIR)\n",
    "Val_Category_count = len(VAL_CATEGORIES)\n",
    "\n",
    "TEST_CATEGORIES = os.listdir(TEST_DIR)\n",
    "Test_Category_count = len(TEST_CATEGORIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying standard rescale factor by which all data values would be multiplied. We're doing this because we deal with images in RGB color model, where pixel values vary between 0 and 255. Such values would be too high for our model to process. This is why I rescale them to interval 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T19:51:00.728664Z",
     "iopub.status.busy": "2021-07-04T19:51:00.728356Z",
     "iopub.status.idle": "2021-07-04T19:51:00.732946Z",
     "shell.execute_reply": "2021-07-04T19:51:00.731797Z",
     "shell.execute_reply.started": "2021-07-04T19:51:00.728632Z"
    }
   },
   "outputs": [],
   "source": [
    "data_iterator = ImageDataGenerator(rescale=1./255,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T19:51:04.169Z",
     "iopub.status.busy": "2021-07-04T19:51:04.168706Z",
     "iopub.status.idle": "2021-07-04T19:51:11.182658Z",
     "shell.execute_reply": "2021-07-04T19:51:11.180853Z",
     "shell.execute_reply.started": "2021-07-04T19:51:04.168973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58388 images belonging to 400 classes.\n",
      "Found 2000 images belonging to 400 classes.\n",
      "Found 2000 images belonging to 400 classes.\n"
     ]
    }
   ],
   "source": [
    "augmented_training_set = ImageDataGenerator(rescale=1./255, rotation_range=40, # Rotate the images randomly by 40 degrees\n",
    "    width_shift_range=0.3, # shift image pixels vertically by 30%\n",
    "    height_shift_range=0.3, # shift image pixels vertically by 30%\n",
    "    zoom_range=0.2, # zoom in on image by 20% \n",
    "    fill_mode='nearest') \n",
    "train_data = augmented_training_set.flow_from_directory(TRAIN_DIR, target_size=(224,224))\n",
    "\n",
    "validation_data = augmented_training_set.flow_from_directory(\n",
    "    directory = VALIDATION_DIR, \n",
    "    batch_size = 32,\n",
    "    shuffle = True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224))\n",
    "\n",
    "test_data = data_iterator.flow_from_directory(\n",
    "    directory = TEST_DIR,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Architecture of this Convolutional Neural Network**\n",
    "\n",
    "1. Convolutional layer - to extract patterns and abstract from low-level features of the images\n",
    "2. Activation layer - activation functions with a same purpose as they have in Multilayer perceptrons. \n",
    "3. Pooling layer - optimization with Max pooling.\n",
    "4. Normalization layer - batch normalization as optimization technique. Conducted after activation, before another convolution\n",
    "5. Dense layer - fully connected layer of the MLP.\n",
    "\n",
    "Input to this convolutional network are RGB images 224 x 224 px with 3 channels. First convolutional layer works with 3 channels, but this does not mean all convolutional layers have to work with these same 3 channels (they usually create activation maps with more channels).\n",
    "\n",
    "Best practice is to use same activation function across all layers. \n",
    "\n",
    "**Strategy of my Learning Process**\n",
    "\n",
    "1. Setup, build and run my Convolutional Neural Network.\n",
    "2. Check my model performance.\n",
    "3. Conduct more experiments with probably different set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T19:51:29.362081Z",
     "iopub.status.busy": "2021-07-04T19:51:29.361815Z",
     "iopub.status.idle": "2021-07-04T20:52:37.634659Z",
     "shell.execute_reply": "2021-07-04T20:52:37.633894Z",
     "shell.execute_reply.started": "2021-07-04T19:51:29.362054Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "IMAGE = load_img(os.getcwd() + \"\\\\testing\\\\ABBOTTS BABBLER\\\\1.jpg\")\n",
    "IMAGEDATA = img_to_array(IMAGE)\n",
    "SHAPE = IMAGEDATA.shape\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# lowest convolutional layer for identification of the edges of birds\n",
    "# input shape is provided, so no deferred initialization https://d2l.ai/chapter_deep-learning-computation/deferred-init.html\n",
    "model.add(Conv2D(64, (3, 3), padding='same', input_shape=SHAPE))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# convolutional layer to learn and store mid-level features of the bird species\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.35))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(BatchNormalization()) \n",
    "model.add(Dropout(0.35))\n",
    "\n",
    "# highest convolutional layer to store complex information about the look of birds\n",
    "model.add(Conv2D(64, (3, 3), padding='same')) \n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.35))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same')) #54x54\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# and finally mlp\n",
    "model.add(Flatten()) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(512)) \n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(Train_Category_count)) \n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Learning**\n",
    "\n",
    "To summarize, in this experiment, task here was to increase accuracy of the model from experiment three. Besides of that we're trying to make learning more efficient by applying Adam optimalization technique. We're also taking into consideration imbalanced dataset we have to deal with (imbalanced in terms of the majority of males, but each folder with images for each of the species contains approximately same number of photos|. In order to do that, we:\n",
    "\n",
    "1. we leave network from 3. experiment in terms of other parameters to be, but <br>\n",
    "2. we will make learning more faster by applying Adam optimalization algorithm <br>\n",
    "3. and we will work with part of the training data augmented, as a downsampling technique to account for imbalance between males and females species <br>\n",
    "4. as we need to account for slightly overfitting on training set in our model from third experiment, we will make changes to second convolutional layer. We will add max pooling to generalize and one more dropout layer. <br>\n",
    "5. in order to spead up learning process we will rely on bigger batches which size has been increased again to 64 <br>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1795/1825 [============================>.] - ETA: 2:38 - loss: 5.0788 - accuracy: 0.0600"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = \"adam\",\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "EPOCHS = 4\n",
    "BATCH_SIZE = 64 # this batch size allows us to perform normalization after each activation layer \n",
    "\n",
    "history = model.fit(train_data, epochs=EPOCHS, validation_data = validation_data, \n",
    "                    steps_per_epoch=len(train_data), validation_steps = len(validation_data), \n",
    "                    callbacks=[EarlyStopping(monitor='val_accuracy', patience = 5, restore_best_weights = True),\n",
    "                    ReduceLROnPlateau(monitor = 'val_loss', factor = 0.7, \n",
    "                                 patience = 2, verbose = 1)])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T20:52:37.636866Z",
     "iopub.status.busy": "2021-07-04T20:52:37.636632Z",
     "iopub.status.idle": "2021-07-04T20:52:49.030372Z",
     "shell.execute_reply": "2021-07-04T20:52:49.029137Z",
     "shell.execute_reply.started": "2021-07-04T20:52:37.636838Z"
    }
   },
   "source": [
    "**Model Evaluation**\n",
    "\n",
    "This network was one of the best in all experiments which I've conducted. It achieved more than 80% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "scores = model.evaluate(test_data, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating Model Performance**\n",
    "\n",
    "See attached document."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

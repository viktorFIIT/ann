{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification of birds to species with Convolutional Neural Network**\n",
    "\n",
    "<u>This notebook documents 1. experiment conducted in 10th of April 2022</u>\n",
    "\n",
    "Dataset I work with is: https://www.kaggle.com/datasets/gpiosenka/100-bird-species/. Check what Convolutional neural networks are all about at https://d2l.ai/chapter_convolutional-neural-networks/index.html before making changes to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T19:48:30.702777Z",
     "iopub.status.busy": "2021-07-04T19:48:30.702432Z",
     "iopub.status.idle": "2021-07-04T19:48:38.452291Z",
     "shell.execute_reply": "2021-07-04T19:48:38.450907Z",
     "shell.execute_reply.started": "2021-07-04T19:48:30.702703Z"
    }
   },
   "outputs": [],
   "source": [
    "# import utilities\n",
    "import os\n",
    "import matplotlib.pyplot as plt # to evaluate model performance\n",
    "\n",
    "import tensorflow as tf # import tensorflow\n",
    "# work with Keras facade\n",
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Activation, Dropout # input, output, hidden layers, activation...\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D # convolutional layer and max pooling\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training set consists of 58 388 RGB images (that means 3 channels), 224px x 224px. Validation set consists of 2000 images and test set consists of 2000 images. There are 356 unique bird species in a training dataset. There are 400 unique bird species in validation dataset and 400 bird species in test dataset too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T19:50:40.928323Z",
     "iopub.status.busy": "2021-07-04T19:50:40.928026Z",
     "iopub.status.idle": "2021-07-04T19:50:40.943859Z",
     "shell.execute_reply": "2021-07-04T19:50:40.943012Z",
     "shell.execute_reply.started": "2021-07-04T19:50:40.928295Z"
    }
   },
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd() # extract dataset from Kaggle to same folder as you have in this notebook\n",
    "\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, 'train')\n",
    "VALIDATION_DIR = os.path.join(BASE_DIR, 'valid')\n",
    "TEST_DIR = os.path.join(BASE_DIR, 'testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T19:50:45.326576Z",
     "iopub.status.busy": "2021-07-04T19:50:45.326284Z",
     "iopub.status.idle": "2021-07-04T19:50:45.362266Z",
     "shell.execute_reply": "2021-07-04T19:50:45.361629Z",
     "shell.execute_reply.started": "2021-07-04T19:50:45.326533Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_CATEGORIES = os.listdir(TRAIN_DIR)\n",
    "Train_Category_count = len(TRAIN_CATEGORIES) # gets you number of classes in training dataset\n",
    "\n",
    "VAL_CATEGORIES = os.listdir(VALIDATION_DIR)\n",
    "Val_Category_count = len(VAL_CATEGORIES)\n",
    "\n",
    "TEST_CATEGORIES = os.listdir(TEST_DIR)\n",
    "Test_Category_count = len(TEST_CATEGORIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying standard rescale factor by which all data values would be multiplied. We're doing this because we deal with images in RGB color model, where pixel values vary between 0 and 255. Such values would be too high for our model to process. This is why I rescale them to interval 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T19:51:00.728664Z",
     "iopub.status.busy": "2021-07-04T19:51:00.728356Z",
     "iopub.status.idle": "2021-07-04T19:51:00.732946Z",
     "shell.execute_reply": "2021-07-04T19:51:00.731797Z",
     "shell.execute_reply.started": "2021-07-04T19:51:00.728632Z"
    }
   },
   "outputs": [],
   "source": [
    "data_iterator = ImageDataGenerator(rescale=1./255,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T19:51:04.169Z",
     "iopub.status.busy": "2021-07-04T19:51:04.168706Z",
     "iopub.status.idle": "2021-07-04T19:51:11.182658Z",
     "shell.execute_reply": "2021-07-04T19:51:11.180853Z",
     "shell.execute_reply.started": "2021-07-04T19:51:04.168973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10825 images belonging to 74 classes.\n",
      "Found 370 images belonging to 74 classes.\n",
      "Found 2000 images belonging to 400 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = data_iterator.flow_from_directory(\n",
    "    directory = TRAIN_DIR, \n",
    "    batch_size = 32, \n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224,224))\n",
    "\n",
    "validation_data = data_iterator.flow_from_directory(\n",
    "    directory = VALIDATION_DIR, \n",
    "    batch_size = 32,\n",
    "    shuffle = True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224))\n",
    "\n",
    "test_data = data_iterator.flow_from_directory(\n",
    "    directory = TEST_DIR,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Architecture of this Convolutional Neural Network**\n",
    "\n",
    "1. Convolutional layer - to extract patterns and abstract from low-level features of the images\n",
    "2. Activation layer - activation functions with a same purpose as they have in Multilayer perceptrons. \n",
    "3. Pooling layer - optimization with Max pooling.\n",
    "4. Normalization layer - batch normalization as optimization technique. Conducted after activation, before another convolution\n",
    "5. Dense layer - fully connected layer of the MLP.\n",
    "\n",
    "Input to this convolutional network are RGB images 224 x 224 px with 3 channels. First convolutional layer works with 3 channels, but this does not mean all convolutional layers have to work with these same 3 channels (they usually create activation maps with more channels).\n",
    "\n",
    "Best practice is to use same activation function across all layers. Nobody knows what they will attribute to if they would be different. \n",
    "\n",
    "**Strategy of my Learning Process**\n",
    "\n",
    "1. Setup, build and run my Convolutional Neural Network.\n",
    "2. Check my model performance.\n",
    "3. Conduct more experiments with probably different set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T19:51:29.362081Z",
     "iopub.status.busy": "2021-07-04T19:51:29.361815Z",
     "iopub.status.idle": "2021-07-04T20:52:37.634659Z",
     "shell.execute_reply": "2021-07-04T20:52:37.633894Z",
     "shell.execute_reply.started": "2021-07-04T19:51:29.362054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "67/67 [==============================] - 40s 591ms/step - loss: 3.4931 - accuracy: 0.1852 - val_loss: 4.8892 - val_accuracy: 0.0054\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 40s 584ms/step - loss: 2.4484 - accuracy: 0.4131 - val_loss: 5.4009 - val_accuracy: 0.0189\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 39s 580ms/step - loss: 1.9287 - accuracy: 0.5327 - val_loss: 6.2441 - val_accuracy: 0.0324\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 40s 592ms/step - loss: 1.5936 - accuracy: 0.6126 - val_loss: 6.5533 - val_accuracy: 0.0243\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 40s 585ms/step - loss: 1.2476 - accuracy: 0.7008 - val_loss: 7.2975 - val_accuracy: 0.0270\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 40s 590ms/step - loss: 1.0694 - accuracy: 0.7459 - val_loss: 7.7681 - val_accuracy: 0.0270\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 40s 591ms/step - loss: 0.8911 - accuracy: 0.7932 - val_loss: 8.1174 - val_accuracy: 0.0270\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 40s 587ms/step - loss: 0.6857 - accuracy: 0.8425 - val_loss: 8.5117 - val_accuracy: 0.0216\n",
      "Epoch 9/10\n",
      " 8/67 [==>...........................] - ETA: 34s - loss: 0.5908 - accuracy: 0.8672"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "IMAGE = load_img(os.getcwd() + \"\\\\testing\\\\ABBOTTS BABBLER\\\\1.jpg\")\n",
    "IMAGEDATA = img_to_array(IMAGE)\n",
    "SHAPE = IMAGEDATA.shape\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# lowest convolutional layer for identification of the edges of birds\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=SHAPE))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "\n",
    "# convolutional layer to learn and store mid-level features of the bird species\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# highest convolutional layer to store complex information about the look of birds\n",
    "model.add(Conv2D(32, (3, 3), padding='same')) \n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "\n",
    "# and finally mlp\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(512)) \n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(Train_Category_count)) \n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer = \"adam\",\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 50 # set up such it enables us to apply batch normalization after activation\n",
    "\n",
    "history = model.fit(train_data, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data = validation_data, steps_per_epoch=len(train_data) / 5, validation_steps = len(validation_data), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-04T20:52:37.636866Z",
     "iopub.status.busy": "2021-07-04T20:52:37.636632Z",
     "iopub.status.idle": "2021-07-04T20:52:49.030372Z",
     "shell.execute_reply": "2021-07-04T20:52:49.029137Z",
     "shell.execute_reply.started": "2021-07-04T20:52:37.636838Z"
    }
   },
   "source": [
    "**Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
